{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75ea5e69",
   "metadata": {},
   "source": [
    "# Machine Learning: Gradiente Descendente Estocástico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238dcd9c",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "8eab28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a5555",
   "metadata": {},
   "source": [
    "Utilizaremos o dataset \"Data for Admission in the University\", disponível no Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd85e926",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/akshaydattatraykhare/data-for-admission-in-the-university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "ab953b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('adm_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f01671",
   "metadata": {},
   "source": [
    "### Visualizando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "47463ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "280218d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
       "       'LOR ', 'CGPA', 'Research', 'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "7d74f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'Chance of Admit ': 'Chance of Admit'}, inplace = True)\n",
    "data.rename(columns = {'LOR ': 'LOR'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "60948456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  \\\n",
       "0           1        337          118                  4  4.5  4.5  9.65   \n",
       "1           2        324          107                  4  4.0  4.5  8.87   \n",
       "2           3        316          104                  3  3.0  3.5  8.00   \n",
       "3           4        322          110                  3  3.5  2.5  8.67   \n",
       "4           5        314          103                  2  2.0  3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit  \n",
       "0         1             0.92  \n",
       "1         1             0.76  \n",
       "2         1             0.72  \n",
       "3         1             0.80  \n",
       "4         0             0.65  "
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f08ae",
   "metadata": {},
   "source": [
    "#### Definições:\n",
    "\n",
    "__Serial No.:__ número de série do estudante (índice + 1)\n",
    "\n",
    "__GRE Score:__ pontuação do estudante no GRE (Graduate Record Examination), um exame padronizado semelhante ao GMAT.\n",
    "\n",
    "__TOEFL Score:__ pontuação no TOEFL, um exame completo de inglês utilizado, entre outras coisas, para admissão em universidades.\n",
    "\n",
    "__University Rating:__ avaliação da universidade (quanto maior, mais conceituada é a universidade na qual o estudante quer entrar).\n",
    "\n",
    "__SOP:__ avaliação do Statement of Purpose, uma redação explicando o propósito do estudante ao aplicar para uma vaga em uma dada graduação em uma universidade.\n",
    "\n",
    "__LOR:__ avaliação da Letter of Recommendation, a carta de recomendação do estudante para a universidade.\n",
    "\n",
    "__CGPA:__ Cumulative Grade Point Average, é uma pontuação utilizada para medir o desempenho médio de um estudante.\n",
    "\n",
    "__Research:__ experiência em pesquisa (1 se o estudante tiver, 0 se não).\n",
    "\n",
    "__Chance of Admit:__ chance de admissão na universidade, indo de 0 a 1 (100%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5787262d",
   "metadata": {},
   "source": [
    "### Definição da label e das features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6666d4",
   "metadata": {},
   "source": [
    "Nossa label (y) será a Chance of Admit.\n",
    "\n",
    "A lista de colunas [\"GRE Score\", \"TOEFL Score\", \"University Rating\", \"SOP\", \"LOR\", \"CGPA\", \"Research\"] contém as features altamente correlacionadas com a chance de admissão na universidade. No nosso caso, iremos tratar apenas das features contínuas, sendo a lista de features que pode ser utilizada a seguinte: features = [\"GRE Score\", \"TOEFL Score\", \"University Rating\", \"SOP\", \"LOR\", \"CGPA\"].\n",
    "\n",
    "Implementaremos o algoritmo de __Gradiente Descendente Estocástico em mini-lotes__  com todas as features contínuas do dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7a1e1f",
   "metadata": {},
   "source": [
    "### Modelo de Regressão Linear com todas as features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7908d7",
   "metadata": {},
   "source": [
    "Com n features, o modelo será da forma:\n",
    "\n",
    "$\\hat{y} = w_{1}x_{1} + w_{2}x_{2} + ... + w_{m}x_{m} + b$\n",
    "\n",
    "Em que $\\hat{y}$ é a estimativa (ou predição) da label $y$, dados os valores das features $x_{1}, x_{2},...,x_{m}$, $(w_{1}, w_{2},...,w_{m})$ é o conjunto de pesos (weight) associado às features e $b$ é chamado de viés (bias).\n",
    "\n",
    "Vamos definir a perda (loss) associada ao modelo através da função de perda $L_{2}$, da mesma forma que foi feito no primeiro modelo. Assim:\n",
    "\n",
    "$loss = \\frac{1}{n}\\sum_{i = 1}^{n} (\\hat{y_{i}} - y_{i})^2$\n",
    "\n",
    "Como queremos reduzir a perda de nosso modelo ao máximo, devemos fazer os parâmetros variarem na direção do  negativo do gradiente de f (esse é o princípio do algoritmo de Gradiente Descendente Estocástico). \n",
    "\n",
    "Nesse contexto, chamemos $\\theta = (w_{1}, w_{2}, ... , w_{m}, b)$. Além disso, definimos o hiperparâmetro $\\alpha$ como a taxa de aprendizagem do modelo, de forma análoga ao modelo anterior.\n",
    "\n",
    "Assim, por meio do gradiente descendente estocástico, o novo valor de $\\theta$, $\\theta'$, será dado pela fórmula:\n",
    "\n",
    "$\\theta' = \\theta - \\alpha \\cdot \\nabla f(w_{1}, w_{2}, ... , w_{m}, b)$\n",
    "\n",
    "Onde $\\nabla f(w_{1}, w_{2}, ... , w_{m}, b) = (\\frac{\\partial f}{\\partial w_{1}}, \\frac{\\partial f}{\\partial w_{2}},..., \\frac{\\partial f}{\\partial w_{m}}, \\frac{\\partial f}{\\partial b})$ é o gradiente de f.\n",
    "\n",
    "Calculando as derivadas parciais:\n",
    "\n",
    "$\\frac{\\partial f}{\\partial w_{k}} = \\frac{2}{n}\\sum_{i = 1}^{n} (\\hat{y}_{i} - y_{i}) \\cdot (x_{k})_{i}$, para toda feature $x_{k}$.\n",
    "\n",
    "$\\frac{\\partial f}{\\partial b} = \\frac{2}{n}\\sum_{i = 1}^{n} (\\hat{y}_{i} - y_{i})$\n",
    "\n",
    "Obtemos os novos valores do peso e do viés após uma iteração:\n",
    "\n",
    "$w_{k}' = w_{k} - \\frac{2 \\alpha}{n}\\sum_{i = 1}^{n} (\\hat{y}_{i} - y_{i}) \\cdot (x_{k})_{i}$, para toda feature $x_{k}$.\n",
    "\n",
    "\n",
    "$b' = b - \\frac{2 \\alpha}{n}\\sum_{i = 1}^{n} (\\hat{y}_{i} - y_{i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0937d19",
   "metadata": {},
   "source": [
    "Com isso em mente, iremos implementar o modelo de regressão linear que se adequa aos dados através do Gradiente Descendente Estocástico em mini-lotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "83e8c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Regression_Model():\n",
    "    def __init__(self, features, label, ws: list,\n",
    "                 b = 0, alpha = 0.1, random_state = 0):\n",
    "        '''Constructor for the Multi_Features_Linear_Regression_Model class. It takes in seven arguments:\n",
    "\n",
    "        - features: a Pandas DataFrame containing the features to be used for training the model;\n",
    "        - label: a Pandas Series containing the label corresponding to the features that will be predicted using the model;\n",
    "        - ws: a list of floats representing the initial values of the weights (coefficients) of the features;\n",
    "        - b: a float representing the initial value of the bias term (default value is 0);\n",
    "        - alpha: a float representing the learning rate (i.e., the size of the step taken in the direction of the gradient during gradient descent) (default value is 0.1);\n",
    "        - random_state: an integer representing the random seed to use for generating random numbers (default value is 0).'''\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "        ws = [float(w) for w in ws]\n",
    "        self.ws = np.array(ws)\n",
    "        self.b = b\n",
    "        self.alpha = alpha\n",
    "        self.rand = np.random.RandomState(random_state)\n",
    "        \n",
    "    def print_parameters(self):\n",
    "        '''Prints the current values of the weights ws and bias b of the model.'''\n",
    "        for i in range(1, len(self.ws) + 1):\n",
    "            print(f'w{i} = {self.ws[i - 1]}')\n",
    "        print (f'b = {self.b}')\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''Takes in a Pandas DataFrame X containing feature values \n",
    "        and returns a NumPy array of predicted values of the label using \n",
    "        the current values of ws and b.'''\n",
    "        n = len(X)\n",
    "        X_copy = X.copy()\n",
    "        X_copy.reset_index(inplace = True, drop = True)\n",
    "        X_copy = X.mul(self.ws)\n",
    "        predictions = np.array(X_copy.sum(axis = 1) + self.b)\n",
    "        return predictions\n",
    "    \n",
    "    def get_loss(self, X, y):\n",
    "        '''Takes in a Pandas DataFrame X containing feature values \n",
    "        and a Pandas Series y containing the corresponding true label values, \n",
    "        and returns the mean squared error loss of the model on the data.'''\n",
    "        n = len(X)\n",
    "        predictions = self.predict(X)\n",
    "        diff = predictions - y\n",
    "        loss = np.mean(diff**2)\n",
    "        return loss\n",
    "    \n",
    "    def __get_Xy_sample(self, begin_index, end_index):\n",
    "        '''Private helper function which from X and y starting in the begin_index \n",
    "        row and ending in end_index row.'''\n",
    "        X = self.features.iloc[begin_index:end_index]\n",
    "        y = self.label.iloc[begin_index:end_index]\n",
    "        return X, y\n",
    "    \n",
    "    def __get_sample_partial_w(self, X, diff, batch_size):\n",
    "        '''Private helper function which gets the partial derivative of loss with \n",
    "        respect to weights for a X sample.'''\n",
    "        partial_w = (2/batch_size) * (diff @ X)\n",
    "        return partial_w\n",
    "    \n",
    "    def __get_sample_partial_b(self, diff, batch_size):\n",
    "        partial_b = (2/batch_size) * np.sum(diff)\n",
    "        return partial_b\n",
    "    \n",
    "    def __batch_update_parameters(self, X, diff, batch_size, inexact_batch_size):\n",
    "        '''Private helper function which updates weights (ws) and bias (b) for a batch.'''\n",
    "        partial_w = self.__get_sample_partial_w(X, diff, inexact_batch_size)\n",
    "        partial_b = self.__get_sample_partial_b(diff, inexact_batch_size)\n",
    "        correction_constant = batch_size/inexact_batch_size\n",
    "        self.ws -= self.alpha * partial_w * correction_constant\n",
    "        self.b -= self.alpha * partial_b * correction_constant\n",
    "        \n",
    "    def __sgd_update_parameters(self, batch_size: int):\n",
    "        '''Private helper function that performs one step of stochastic gradient descent on the model's parameters (ws and b). \n",
    "        It takes in a single argument batch_size, which is the number of samples to use in the mini-batch for this step of gradient descent. \n",
    "        The function first selects mini-batches from the training data, and then performs an update to the model's parameters \n",
    "        using the gradient of the mean squared error loss with respect to the parameters for each mini-batch.\n",
    "        The update is performed using the learning rate alpha.'''\n",
    "        num_of_data_rows = len(self.label)\n",
    "        inexact_batch_size = num_of_data_rows % batch_size\n",
    "        num_of_exact_batches = int(num_of_data_rows/batch_size)\n",
    "        for exact_batch in range(1, num_of_exact_batches + 1):\n",
    "            begin_index = (exact_batch - 1) * batch_size\n",
    "            end_index = exact_batch * batch_size\n",
    "            X, y = self.__get_Xy_sample(begin_index, end_index)\n",
    "            predictions = self.predict(X)\n",
    "            diff = predictions - y\n",
    "            self.__batch_update_parameters(X, diff, batch_size, batch_size)\n",
    "        if inexact_batch_size != 0:\n",
    "            begin_index = (num_of_exact_batches) * batch_size + 1\n",
    "            end_index = num_of_data_rows + 1\n",
    "            X, y = self.__get_Xy_sample(begin_index, end_index)\n",
    "            predictions = self.predict(X)\n",
    "            diff = predictions - y\n",
    "            self.__batch_update_parameters(X, diff, batch_size, inexact_batch_size)\n",
    "        \n",
    "    def sgd(self, iterations: int, batch_size: float, print_loss: bool): # stochastic gradient descent\n",
    "        '''Performs stochastic gradient descent for a specified number of iterations. It takes in three arguments:\n",
    "\n",
    "        - iterations: an integer representing the number of iterations of gradient descent to perform\n",
    "        - batch_size: a float representing the number of samples to use in each mini-batch for each step of gradient descent\n",
    "        - print_loss: a boolean indicating whether to print the loss after each iteration of gradient descent. \n",
    "        If True, the loss will be printed; if False, the loss will not be printed.'''\n",
    "        for i in range(0, iterations):\n",
    "            self.__sgd_update_parameters(batch_size)\n",
    "            if print_loss:\n",
    "                print(f'loss = {self.get_loss(self.features, self.label)}')\n",
    "    \n",
    "    @staticmethod\n",
    "    def shuffle_data(data, random_state):\n",
    "        '''Shuffles a Pandas Dataframe's data.'''\n",
    "        rand = np.random.RandomState(random_state)\n",
    "        return data.reindex(rand.permutation(data.index))\n",
    "    \n",
    "    @staticmethod\n",
    "    def train_val_test_split(X, y, test_split_factor: float, val_split_factor: float):\n",
    "        '''Get train, validation and test Pandas Dataframes from X (features) and y (label).'''\n",
    "        num_of_data_rows = len(y)\n",
    "        test_size = int(test_split_factor * n)\n",
    "        val_size = int(val_split_factor * n)\n",
    "        X_test = X.iloc[0:test_size]\n",
    "        y_test = y.iloc[0:test_size]\n",
    "        X_val = X.iloc[test_size:test_size + val_size]\n",
    "        y_val = y.iloc[test_size:test_size + val_size]\n",
    "        X_train = X.iloc[test_size + val_size:num_of_data_rows]\n",
    "        y_train = y.iloc[test_size + val_size:num_of_data_rows]\n",
    "        return X_test, y_test, X_val, y_val, X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "dbf025ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"GRE Score\", \"TOEFL Score\", \"University Rating\", \"SOP\", \"LOR\", \"CGPA\"]\n",
    "label = 'Chance of Admit'\n",
    "X_train = data[features]\n",
    "y_train = data[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "5454c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(feature, train_feature):\n",
    "    minimum = min(train_feature)\n",
    "    maximum = max(train_feature)\n",
    "    return (feature - minimum)/(maximum - minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "0af9e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_X_train = X_train.copy()\n",
    "X_train_scaled = X_train.copy()\n",
    "for feature in features:\n",
    "    X_train_scaled[feature] = scale(X_train_scaled[feature], unscaled_X_train[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "9e176aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = [0, 0, 0, 0, 0, 0]\n",
    "b = 0\n",
    "alpha = 0.001\n",
    "multi_features_model = Linear_Regression_Model(features = X_train_scaled, \n",
    "                                               label = y_train, ws = ws, b = b, alpha = alpha,\n",
    "                                               random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "7da95491",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = 0.0\n",
      "w2 = 0.0\n",
      "w3 = 0.0\n",
      "w4 = 0.0\n",
      "w5 = 0.0\n",
      "w6 = 0.0\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "multi_features_model.print_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "f1c06f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_features_model.sgd(iterations = 100, batch_size = 20, print_loss = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "f75c961a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0061997711355344645"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_features_model.get_loss(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "11d3c5fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = 0.131551318370844\n",
      "w2 = 0.13288348783321113\n",
      "w3 = 0.10749988946457083\n",
      "w4 = 0.12838007846968924\n",
      "w5 = 0.14179470909567662\n",
      "w6 = 0.14573570611596243\n",
      "b = 0.2693263331497966\n"
     ]
    }
   ],
   "source": [
    "multi_features_model.print_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "aab0d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(y_train)\n",
    "pred = np.zeros(n)\n",
    "pred = multi_features_model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "1a6be79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_pred = data.assign(Predictions = pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "360d9899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.966528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.827639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.657297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.713453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.580404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.771446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.747062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.945325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.712233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.950049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  \\\n",
       "0             1        337          118                  4  4.5  4.5  9.65   \n",
       "1             2        324          107                  4  4.0  4.5  8.87   \n",
       "2             3        316          104                  3  3.0  3.5  8.00   \n",
       "3             4        322          110                  3  3.5  2.5  8.67   \n",
       "4             5        314          103                  2  2.0  3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...  ...   ...   \n",
       "395         396        324          110                  3  3.5  3.5  9.04   \n",
       "396         397        325          107                  3  3.0  3.5  9.11   \n",
       "397         398        330          116                  4  5.0  4.5  9.45   \n",
       "398         399        312          103                  3  3.5  4.0  8.78   \n",
       "399         400        333          117                  4  5.0  4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit  Predictions  \n",
       "0           1             0.92     0.966528  \n",
       "1           1             0.76     0.827639  \n",
       "2           1             0.72     0.657297  \n",
       "3           1             0.80     0.713453  \n",
       "4           0             0.65     0.580404  \n",
       "..        ...              ...          ...  \n",
       "395         1             0.82     0.771446  \n",
       "396         1             0.84     0.747062  \n",
       "397         1             0.91     0.945325  \n",
       "398         0             0.67     0.712233  \n",
       "399         1             0.95     0.950049  \n",
       "\n",
       "[400 rows x 10 columns]"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
