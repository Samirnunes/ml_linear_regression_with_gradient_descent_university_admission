{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0072cf56",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "90b030c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01351e2e",
   "metadata": {},
   "source": [
    "## Importando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "f4081727",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('adm_data.csv')\n",
    "data.rename(columns = {'Chance of Admit ': 'Chance of Admit'}, inplace = True)\n",
    "data.rename(columns = {'LOR ': 'LOR'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "daffc0a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  \\\n",
       "0           1        337          118                  4  4.5  4.5  9.65   \n",
       "1           2        324          107                  4  4.0  4.5  8.87   \n",
       "2           3        316          104                  3  3.0  3.5  8.00   \n",
       "3           4        322          110                  3  3.5  2.5  8.67   \n",
       "4           5        314          103                  2  2.0  3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit  \n",
       "0         1             0.92  \n",
       "1         1             0.76  \n",
       "2         1             0.72  \n",
       "3         1             0.80  \n",
       "4         0             0.65  "
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "5ce0b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR', 'CGPA', 'Research']\n",
    "label = 'Chance of Admit'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c2ff1",
   "metadata": {},
   "source": [
    "### Correlação dos dados com a chance de admissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "878a9051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0.042336\n",
       "GRE Score            0.802610\n",
       "TOEFL Score          0.791594\n",
       "University Rating    0.711250\n",
       "SOP                  0.675732\n",
       "LOR                  0.669889\n",
       "CGPA                 0.873289\n",
       "Research             0.553202\n",
       "Chance of Admit      1.000000\n",
       "Name: Chance of Admit, dtype: float64"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()['Chance of Admit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9295fff8",
   "metadata": {},
   "source": [
    "Temos, de fato, dados altamente correlacionados com a chance de admissão dos estudantes nas universidades escolhidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b275618",
   "metadata": {},
   "source": [
    "## Modelo de Regressão Linear Anteriormente Implementado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "7a89f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Regression_Model():\n",
    "    def __init__(self, features, label, ws: list,\n",
    "                 b = 0, alpha = 0.1, random_state = 0):\n",
    "        '''Constructor for the Multi_Features_Linear_Regression_Model class. It takes in seven arguments:\n",
    "\n",
    "        - features: a Pandas DataFrame containing the features to be used for training the model;\n",
    "        - label: a Pandas Series containing the label corresponding to the features that will be predicted using the model;\n",
    "        - ws: a list of floats representing the initial values of the weights (coefficients) of the features;\n",
    "        - b: a float representing the initial value of the bias term (default value is 0);\n",
    "        - alpha: a float representing the learning rate (i.e., the size of the step taken in the direction of the gradient during gradient descent) (default value is 0.1);\n",
    "        - random_state: an integer representing the random seed to use for generating random numbers (default value is 0).'''\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "        ws = [float(w) for w in ws]\n",
    "        self.ws = np.array(ws)\n",
    "        self.b = b\n",
    "        self.alpha = alpha\n",
    "        self.rand = np.random.RandomState(random_state)\n",
    "        \n",
    "    def print_parameters(self):\n",
    "        '''Prints the current values of the weights ws and bias b of the model.'''\n",
    "        for i in range(1, len(self.ws) + 1):\n",
    "            print(f'w{i} = {self.ws[i - 1]}')\n",
    "        print (f'b = {self.b}')\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''Takes in a Pandas DataFrame X containing feature values \n",
    "        and returns a NumPy array of predicted values of the label using \n",
    "        the current values of ws and b.'''\n",
    "        n = len(X)\n",
    "        X_copy = X.copy()\n",
    "        X_copy.reset_index(inplace = True, drop = True)\n",
    "        X_copy = X.mul(self.ws)\n",
    "        predictions = np.array(X_copy.sum(axis = 1) + self.b)\n",
    "        return predictions\n",
    "    \n",
    "    def get_loss(self, X, y):\n",
    "        '''Takes in a Pandas DataFrame X containing feature values \n",
    "        and a Pandas Series y containing the corresponding true label values, \n",
    "        and returns the mean squared error loss of the model on the data.'''\n",
    "        n = len(X)\n",
    "        predictions = self.predict(X)\n",
    "        diff = predictions - y\n",
    "        loss = np.mean(diff**2)\n",
    "        return loss\n",
    "    \n",
    "    def __get_Xy_sample(self, begin_index, end_index):\n",
    "        '''Private helper function which from X and y starting in the begin_index \n",
    "        row and ending in end_index row.'''\n",
    "        X = self.features.iloc[begin_index:end_index]\n",
    "        y = self.label.iloc[begin_index:end_index]\n",
    "        return X, y\n",
    "    \n",
    "    def __get_sample_partial_w(self, X, diff, batch_size):\n",
    "        '''Private helper function which gets the partial derivative of loss with \n",
    "        respect to weights for a sample (X).'''\n",
    "        partial_w = (2/batch_size) * (diff @ X)\n",
    "        return partial_w\n",
    "    \n",
    "    def __get_sample_partial_b(self, diff, batch_size):\n",
    "        partial_b = (2/batch_size) * np.sum(diff)\n",
    "        return partial_b\n",
    "    \n",
    "    def __batch_update_parameters(self, X, diff, batch_size, inexact_batch_size):\n",
    "        '''Private helper function which updates weights (ws) and bias (b) for a batch.'''\n",
    "        partial_w = self.__get_sample_partial_w(X, diff, inexact_batch_size)\n",
    "        partial_b = self.__get_sample_partial_b(diff, inexact_batch_size)\n",
    "        correction_constant = batch_size/inexact_batch_size\n",
    "        self.ws -= self.alpha * partial_w * correction_constant\n",
    "        self.b -= self.alpha * partial_b * correction_constant\n",
    "        \n",
    "    def __sgd_update_parameters(self, batch_size: int):\n",
    "        '''Private helper function that performs one step of stochastic gradient descent on the model's parameters (ws and b). \n",
    "        It takes in a single argument batch_size, which is the number of samples to use in the mini-batch for this step of gradient descent. \n",
    "        The function first selects mini-batches from the training data, and then performs an update to the model's parameters \n",
    "        using the gradient of the mean squared error loss with respect to the parameters for each mini-batch.\n",
    "        The update is performed using the learning rate alpha.'''\n",
    "        num_of_data_rows = len(self.label)\n",
    "        inexact_batch_size = num_of_data_rows % batch_size\n",
    "        num_of_exact_batches = int(num_of_data_rows/batch_size)\n",
    "        for exact_batch in range(1, num_of_exact_batches + 1):\n",
    "            begin_index = (exact_batch - 1) * batch_size\n",
    "            end_index = exact_batch * batch_size\n",
    "            X, y = self.__get_Xy_sample(begin_index, end_index)\n",
    "            predictions = self.predict(X)\n",
    "            diff = predictions - y\n",
    "            self.__batch_update_parameters(X, diff, batch_size, batch_size)\n",
    "        if inexact_batch_size != 0:\n",
    "            begin_index = (num_of_exact_batches) * batch_size + 1\n",
    "            end_index = num_of_data_rows + 1\n",
    "            X, y = self.__get_Xy_sample(begin_index, end_index)\n",
    "            predictions = self.predict(X)\n",
    "            diff = predictions - y\n",
    "            self.__batch_update_parameters(X, diff, batch_size, inexact_batch_size)\n",
    "        \n",
    "    def sgd(self, iterations: int, batch_size: float, print_loss: bool): # stochastic gradient descent\n",
    "        '''Performs stochastic gradient descent for a specified number of iterations. It takes in three arguments:\n",
    "\n",
    "        - iterations: an integer representing the number of iterations of gradient descent to perform\n",
    "        - batch_size: a float representing the number of samples to use in each mini-batch for each step of gradient descent\n",
    "        - print_loss: a boolean indicating whether to print the loss after each iteration of gradient descent. \n",
    "        If True, the loss will be printed; if False, the loss will not be printed.'''\n",
    "        for i in range(0, iterations):\n",
    "            self.__sgd_update_parameters(batch_size)\n",
    "            if print_loss:\n",
    "                print(f'loss = {self.get_loss(self.features, self.label)}')\n",
    "    \n",
    "    @staticmethod\n",
    "    def shuffle_data(data, random_state):\n",
    "        '''Shuffles a Pandas Dataframe's data.'''\n",
    "        rand = np.random.RandomState(random_state)\n",
    "        return data.reindex(rand.permutation(data.index))\n",
    "    \n",
    "    @staticmethod\n",
    "    def train_val_test_split(X, y, test_split_factor: float, val_split_factor: float):\n",
    "        '''Get train, validation and test Pandas Dataframes from X (features) and y (label).'''\n",
    "        num_of_data_rows = len(y)\n",
    "        test_size = int(test_split_factor * num_of_data_rows)\n",
    "        val_size = int(val_split_factor * num_of_data_rows)\n",
    "        X_test = X.iloc[0:test_size]\n",
    "        y_test = y.iloc[0:test_size]\n",
    "        X_val = X.iloc[test_size:test_size + val_size]\n",
    "        y_val = y.iloc[test_size:test_size + val_size]\n",
    "        X_train = X.iloc[test_size + val_size:num_of_data_rows]\n",
    "        y_train = y.iloc[test_size + val_size:num_of_data_rows]\n",
    "        return X_test, y_test, X_val, y_val, X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e449da34",
   "metadata": {},
   "source": [
    "## Treinamento, Validação e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c8b491",
   "metadata": {},
   "source": [
    "Vamos treinar o modelo no dataset que temos. Para tal, iremos dividir o dataframe 'data' em três partes: training, validation e test. A primeira parte será utilizada para o treinamento do modelo; a segunda, para validar o modelo em um conjunto de dados diferentes daqueles usados no treinamento e, se necessário, para corrigir os parâmetros do modelo; e a terceira será utilizada como uma forma de teste final para o modelo, evitando o overfitting nos dados de validação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4772bfe",
   "metadata": {},
   "source": [
    "### Função para separar os dados em treinamento, validação e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909b6c67",
   "metadata": {},
   "source": [
    "Tal função está implementada dentro da classe Linear_Regression_Model, juntamente da função shuffle_data, utilizada para embaralhar os dados no dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a08bf9c",
   "metadata": {},
   "source": [
    "#### Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "ba330a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "data_shuffled = Linear_Regression_Model.shuffle_data(data, random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd005f5b",
   "metadata": {},
   "source": [
    "#### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e07e6577",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_shuffled[features]\n",
    "y = data_shuffled[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "bc7b8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, X_val, y_val, X_train, y_train = Linear_Regression_Model.train_val_test_split(X, y, test_split_factor = 0.2, val_split_factor = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "755d5b19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>323</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>340</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>303</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>318</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  Research\n",
       "281        317          110                  3  4.0  4.5  9.11         1\n",
       "133        323          112                  5  4.0  4.5  8.78         0\n",
       "33         340          114                  5  4.0  4.0  9.60         1\n",
       "378        303           98                  1  2.0  2.5  7.65         0\n",
       "162        318          109                  3  3.0  3.0  8.50         0"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "3907f92e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 7)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "e636016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>319</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>325</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>320</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>329</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>309</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  Research\n",
       "336        319          110                  3  3.0  2.5  8.79         0\n",
       "64         325          111                  3  3.0  3.5  8.70         0\n",
       "55         320          103                  3  3.0  3.0  7.70         0\n",
       "106        329          111                  4  4.5  4.5  9.18         1\n",
       "300        309          106                  2  2.5  2.5  8.00         0"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "efde4d4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 7)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "5f56812c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>309</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>308</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>326</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>306</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>316</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  Research\n",
       "132        309          105                  5  3.5  3.5  8.56         0\n",
       "309        308          110                  4  3.5  3.0  8.60         0\n",
       "341        326          110                  3  3.5  3.5  8.76         1\n",
       "196        306          105                  2  3.0  2.5  8.26         0\n",
       "246        316          105                  3  3.0  3.5  8.73         0"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "187fbd8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 7)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88c0d8a",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28931ae",
   "metadata": {},
   "source": [
    "#### Obs: o pré-processamento deve vir depois do processo de split, para evitar adicionar viés aos dados de teste por influência dos dados de treino."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f31e29",
   "metadata": {},
   "source": [
    "### Mudando a escala dos dados para [0, 1]\n",
    "\n",
    "Transformaremos [min, max] -> [0, 1] para cada coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "136eaeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(feature, train_feature):\n",
    "    minimum = min(train_feature)\n",
    "    maximum = max(train_feature)\n",
    "    return (feature - minimum)/(maximum - minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "74ff05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_X_train= X_train.copy()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "for feature in features:\n",
    "    X_train_scaled[feature] = scale(X_train_scaled[feature], unscaled_X_train[feature])\n",
    "    X_val_scaled[feature] = scale(X_val_scaled[feature], unscaled_X_train[feature])\n",
    "    X_test_scaled[feature] = scale(X_test_scaled[feature], unscaled_X_train[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d5d90",
   "metadata": {},
   "source": [
    "### Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "e7b40d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = list(np.zeros(len(features)))\n",
    "b = 0\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "20d9f373",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Linear_Regression_Model(features = X_train_scaled,\n",
    "                                label = y_train, ws = ws, b = b, alpha = alpha,\n",
    "                                random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "25fe929a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5472704166666664"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_loss(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "e9392188",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sgd(iterations = 20, batch_size = 20, print_loss = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "49fb5dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006264075583736085"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_loss(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4da991",
   "metadata": {},
   "source": [
    "### Aplicando o modelo nos dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "88b4cf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6557017 , 0.70305719, 0.59730247, 0.89060253, 0.5445739 ,\n",
       "       0.77881433, 0.57859271, 0.72059422, 0.78462908, 0.83548448,\n",
       "       0.76265111, 0.9432327 , 0.54210444, 0.4418304 , 0.88378508,\n",
       "       0.58325857, 0.78436057, 0.53556387, 0.70482699, 0.73613155,\n",
       "       0.68196316, 0.70294454, 0.82437069, 0.41984719, 0.73053848,\n",
       "       0.68791805, 0.99878171, 0.57341877, 0.69437932, 0.57717102,\n",
       "       0.54337459, 0.80047497, 0.66462986, 0.67478632, 0.85516042,\n",
       "       0.88217881, 0.95015131, 0.79218262, 0.59596412, 0.56173711,\n",
       "       0.54642126, 0.63886301, 0.92691074, 0.60084217, 0.38875232,\n",
       "       0.89811956, 0.97653282, 0.6559812 , 0.71003713, 0.55552899,\n",
       "       0.89480409, 0.61896925, 0.71770824, 0.47392205, 0.78949147,\n",
       "       0.56920564, 0.85905487, 0.67418979, 0.488487  , 0.70821034,\n",
       "       0.86648915, 0.72341319, 0.58016917, 0.69105914, 0.68270712,\n",
       "       0.68236031, 0.51943459, 0.79621923, 0.8914757 , 0.63034631,\n",
       "       0.77080327, 0.99951582, 0.70875267, 0.68820038, 0.95835103,\n",
       "       0.70226869, 0.7598612 , 0.80489229, 0.70563219, 0.65893654])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "9ab2b929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006077148662474384"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_loss(X_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63adc15e",
   "metadata": {},
   "source": [
    "As perdas relativas à train_data e à val_data estão muito próximas e estão suficientemente baixas. Logo, falta somente conferirmos se o modelo não está overfitted por meio test_data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c510c89b",
   "metadata": {},
   "source": [
    "### Aplicando o modelo nos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "527862f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69354442, 0.67513609, 0.77692819, 0.55917745, 0.65841302,\n",
       "       0.55469064, 0.64759718, 0.64776975, 0.85711024, 0.94761454,\n",
       "       0.4290851 , 0.9039306 , 0.68751743, 0.4128821 , 0.87468998,\n",
       "       0.5230491 , 0.60762178, 0.77641901, 0.56938103, 0.71999253,\n",
       "       0.92333369, 0.8504334 , 0.60789145, 0.39603348, 0.82293961,\n",
       "       0.57012286, 0.50464043, 0.61590579, 0.94218761, 0.64324266,\n",
       "       0.62435771, 0.74817081, 0.79464783, 0.48650375, 0.75345322,\n",
       "       0.75495081, 0.71343077, 0.87307736, 0.58818723, 0.9437957 ,\n",
       "       0.74190683, 0.622092  , 0.73891748, 0.83434425, 0.8092228 ,\n",
       "       0.66115436, 0.52452834, 0.7269177 , 0.52952235, 0.54418841,\n",
       "       0.59516692, 0.75529981, 0.59598304, 0.9304447 , 0.74866488,\n",
       "       0.69978438, 0.80704644, 0.75862294, 0.77946336, 0.88662255,\n",
       "       0.71539043, 0.36385084, 0.55508344, 0.48541482, 0.88834729,\n",
       "       0.77590721, 0.67204376, 0.889068  , 0.70111474, 0.72271404,\n",
       "       0.58106568, 0.87443245, 0.79114393, 0.63001663, 0.92029984,\n",
       "       0.64258886, 0.55752019, 0.5560706 , 0.89140659, 0.4367743 ])"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "8fcea5db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006625737302429019"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_loss(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c27a16",
   "metadata": {},
   "source": [
    "O resultado está bem coerente e configura uma possível predição. Assim, conseguimos treinar o modelo, validá-lo e testá-lo com sucesso!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb8d4ff",
   "metadata": {},
   "source": [
    "### Parâmetros finais do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "8ab16874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = 0.11530799078359782\n",
      "w2 = 0.1176373524513257\n",
      "w3 = 0.08892145823187657\n",
      "w4 = 0.11431736723098168\n",
      "w5 = 0.1331000425434934\n",
      "w6 = 0.13720430956388835\n",
      "w7 = 0.05883796135278343\n",
      "b = 0.27415540401434535\n"
     ]
    }
   ],
   "source": [
    "model.print_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
