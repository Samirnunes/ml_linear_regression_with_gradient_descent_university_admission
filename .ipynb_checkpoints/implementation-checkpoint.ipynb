{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75ea5e69",
   "metadata": {},
   "source": [
    "# Machine Learning: Gradiente Descendente Estocástico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238dcd9c",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8eab28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0) # Para termos sempre os mesmos números aleatórios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a5555",
   "metadata": {},
   "source": [
    "Utilizaremos o dataset \"Data for Admission in the University\", disponível no Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab953b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('adm_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f01671",
   "metadata": {},
   "source": [
    "### Visualizando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47463ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "280218d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
       "       'LOR ', 'CGPA', 'Research', 'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d74f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'Chance of Admit ': 'Chance of Admit'}, inplace = True)\n",
    "data.rename(columns = {'LOR ': 'LOR'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "60948456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  \\\n",
       "0           1        337          118                  4  4.5  4.5  9.65   \n",
       "1           2        324          107                  4  4.0  4.5  8.87   \n",
       "2           3        316          104                  3  3.0  3.5  8.00   \n",
       "3           4        322          110                  3  3.5  2.5  8.67   \n",
       "4           5        314          103                  2  2.0  3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit  \n",
       "0         1             0.92  \n",
       "1         1             0.76  \n",
       "2         1             0.72  \n",
       "3         1             0.80  \n",
       "4         0             0.65  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f08ae",
   "metadata": {},
   "source": [
    "#### Definições:\n",
    "\n",
    "__Serial No.:__ número de série do estudante (índice + 1)\n",
    "\n",
    "__GRE Score:__ pontuação do estudante no GRE (Graduate Record Examination), um exame padronizado semelhante ao GMAT.\n",
    "\n",
    "__TOEFL Score:__ pontuação no TOEFL, um exame completo de inglês utilizado, entre outras coisas, para admissão em universidades.\n",
    "\n",
    "__University Rating:__ avaliação da universidade (quanto maior, mais conceituada é a universidade na qual o estudante quer entrar).\n",
    "\n",
    "__SOP:__ avaliação do Statement of Purpose, uma redação explicando o propósito do estudante ao aplicar para uma vaga em uma dada graduação em uma universidade.\n",
    "\n",
    "__LOR:__ avaliação da Letter of Recommendation, a carta de recomendação do estudante para a universidade.\n",
    "\n",
    "__CGPA:__ Cumulative Grade Point Average, é uma pontuação utilizada para medir o desempenho médio de um estudante.\n",
    "\n",
    "__Research:__ experiência em pesquisa (1 se o estudante tiver, 0 se não).\n",
    "\n",
    "__Chance of Admit:__ chance de admissão na universidade, indo de 0 a 1 (100%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5787262d",
   "metadata": {},
   "source": [
    "### Definição da label e das features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6666d4",
   "metadata": {},
   "source": [
    "Nossa label (y) será a Chance of Admit.\n",
    "\n",
    "A lista de colunas [\"GRE Score\", \"TOEFL Score\", \"University Rating\", \"SOP\", \"LOR\", \"CGPA\", \"Research\"] contém as features altamente correlacionadas com a chance de admissão na universidade. No nosso caso, iremos tratar apenas das features contínuas, sendo a lista de features que pode ser utilizada a seguinte: features = [\"GRE Score\", \"TOEFL Score\", \"University Rating\", \"SOP\", \"LOR\", \"CGPA\"].\n",
    "\n",
    "Implementaremos o algoritmo de __Gradiente Descendente Estocástico em mini-lotes__  nos seguintes casos:\n",
    "\n",
    "1) Modelo de Regressão Linear com 1 feature.\n",
    "\n",
    "2) Modelo de Regressão Linear com todas as features contínuas do dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9218ea7f",
   "metadata": {},
   "source": [
    "### 1) Modelo de Regressão Linear com 1 feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6682d1",
   "metadata": {},
   "source": [
    "O modelo será da forma: \n",
    "\n",
    "$\\hat{y} = w_{1}x_{1} + b$\n",
    "\n",
    "Em que $\\hat{y}$ é a estimativa (ou predição) da label $y$, dado um valor da feature $x_{1}$, $w_{1}$ é o peso (weight) associado à feature $x_{1}$ e $b$ é chamado de viés (bias)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083a440",
   "metadata": {},
   "source": [
    "Vamos definir a perda (loss) associada ao modelo através da função de perda $L_{2}$, também chamada de squared loss. Assim:\n",
    "\n",
    "$loss = \\frac{1}{n}\\sum_{i = 1}^{n} (\\hat{y_{i}} - y_{i})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d32012d",
   "metadata": {},
   "source": [
    "Em que n é o número de dados que iremos utilizar no aprendizado de nosso modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eaf8f2",
   "metadata": {},
   "source": [
    "Podemos escrevê-la ainda como função explícita dos parâmetros $w_{1}$ e $b$:\n",
    "\n",
    "$loss = f(w_{1}, b) = \\frac{1}{n}\\sum_{i = 1}^{n} (w_{1}(x_{1})_{i} + b - y_{i})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610d4265",
   "metadata": {},
   "source": [
    "Como queremos reduzir a perda de nosso modelo ao máximo, devemos fazer os parâmetros variarem na direção do  negativo do gradiente de f (esse é o princípio do algoritmo de Gradiente Descendente Estocástico). \n",
    "\n",
    "Nesse contexto, chamemos $\\theta = (w_{1}, b)$. Além disso, definimos o hiperparâmetro $\\alpha$ como sendo a taxa de aprendizagem do modelo, a qual afeta diretamente a velocidade de convergência do modelo para os parâmetros ideais.\n",
    "\n",
    "Assim, o novo valor de $\\theta$, $\\theta'$, será dado pela fórmula:\n",
    "\n",
    "$\\theta' = \\theta - \\alpha \\cdot \\nabla f(w_{1}, b)$\n",
    "\n",
    "Onde $\\nabla f(w_{1}, b) = (\\frac{\\partial f}{\\partial w_{1}}, \\frac{\\partial f}{\\partial b})$ é o gradiente de f."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afe6a26",
   "metadata": {},
   "source": [
    "Calculando as derivadas parciais:\n",
    "\n",
    "$\\frac{\\partial f}{\\partial w_{1}} = \\frac{2}{n}\\sum_{i = 1}^{n} (w_{1}(x_{1})_{i} + b - y_{i}) \\cdot (x_{1})_{i}$\n",
    "\n",
    "$\\frac{\\partial f}{\\partial b} = \\frac{2}{n}\\sum_{i = 1}^{n} (w_{1}(x_{1})_{i} + b - y_{i})$\n",
    "\n",
    "Obtemos os novos valores do peso e do viés após uma iteração:\n",
    "\n",
    "$w_{1}' = w_{1} - \\frac{2 \\alpha}{n}\\sum_{i = 1}^{n} (w_{1}(x_{1})_{i} + b - y_{i}) \\cdot (x_{1})_{i}$\n",
    "\n",
    "$b' = b - \\frac{2 \\alpha}{n}\\sum_{i = 1}^{n} (w_{1}(x_{1})_{i} + b - y_{i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410cece1",
   "metadata": {},
   "source": [
    "Com isso em mente, iremos implementar o modelo de regressão linear que se adequa aos dados através do Gradiente Descendente Estocástico em mini-lotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39e3ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Regression_Model():\n",
    "    def __init__(self, data, feature_name: str, label_name: str, w1: float, b: float, alpha: float):\n",
    "        self.feature = data[feature_name]\n",
    "        self.label = data[label_name]\n",
    "        self.w1 = w1\n",
    "        self.b = b\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def print_parameters(self):\n",
    "        print(f'w1 = {self.w1}\\nb = {self.b}')\n",
    "        \n",
    "    def get_prediction(self, x1: float):\n",
    "        return self.w1*x1 + self.b\n",
    "        \n",
    "    def get_loss(self):\n",
    "        loss = 0\n",
    "        n = len(self.label)\n",
    "        for (x1, y) in zip(self.feature, self.label):\n",
    "            loss += (1/n)*(self.get_prediction(x1) - y)**2\n",
    "        return loss\n",
    "        \n",
    "    def sgd_update_parameters(self, batch_size: int):\n",
    "        index_list = list(range(0, len(self.label)))\n",
    "        random_indices = np.random.choice(index_list, size = batch_size, replace = True) # bootstrap sample\n",
    "        x1_sample = self.feature.iloc[random_indices]\n",
    "        y_sample = self.label.iloc[random_indices]\n",
    "        old_w1 = self.w1\n",
    "        old_b = self.b\n",
    "        for (x1, y) in zip(x1_sample, y_sample):\n",
    "            partial_w1 = (2/batch_size) * (old_w1*x1 + old_b - y) * x1\n",
    "            partial_b = (2/batch_size) * (old_w1*x1 + old_b - y)\n",
    "            self.w1 -= self.alpha * partial_w1\n",
    "            self.b -= self.alpha * partial_b\n",
    "        \n",
    "    def sgd(self, iterations: int, batch_size: float, print_loss: bool): # stochastic gradient descent\n",
    "        for i in range(0, iterations):\n",
    "            self.sgd_update_parameters(batch_size)\n",
    "            if print_loss:\n",
    "                print(f'loss = {self.get_loss()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f2455c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'CGPA'\n",
    "label_name = 'Chance of Admit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d2844d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Linear_Regression_Model(data = data, feature_name = feature_name, label_name = label_name, w1 = 0.2, b = -1, alpha = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7f1faf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sgd(iterations = 10000, batch_size = 10, print_loss = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "20e93c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = 0.20917154818244124\n",
      "b = -1.0413072414386886\n"
     ]
    }
   ],
   "source": [
    "model.print_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0037d",
   "metadata": {},
   "source": [
    "### Plotando a reta de regressão obtida através do SGD e comparando com a curva analítica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de54bd1a",
   "metadata": {},
   "source": [
    "#### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e8fdeb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec631380",
   "metadata": {},
   "source": [
    "#### Obtendo os parâmetros da curva analítica através do numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4eee01a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_np, b_np = np.polyfit(data[feature_name], data[label_name], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3fb16ccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20884722950069112"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "238935e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.071511662934231"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b500a",
   "metadata": {},
   "source": [
    "#### Obtendo os pontos da reta SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1327dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 10.01, 0.01)\n",
    "y_sgd = []\n",
    "for x1 in x:\n",
    "    y_sgd.append(model.get_prediction(x1))\n",
    "y_sgd = np.array(y_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c899869d",
   "metadata": {},
   "source": [
    "#### Plot das retas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a95674fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2169414f790>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data[feature_name], data[label_name], 'o', color = 'gray') # Plot dos dados\n",
    "plt.plot(x, y_sgd, color = 'orange') # Plot da reta SGD\n",
    "plt.plot(x, m_np*x + b_np, color = 'red') # Plot da reta de regressão analítica\n",
    "plt.xlim([7.0, 10.0])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(['Data', 'SGD', 'Analytical'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7a1e1f",
   "metadata": {},
   "source": [
    "### 2) Modelo de Regressão Linear com todas as features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7908d7",
   "metadata": {},
   "source": [
    "Com n features, o modelo será da forma:\n",
    "\n",
    "$\\hat{y} = w_{1}x_{1} + w_{2}x_{2} + ... + w_{n}x_{n} + b$\n",
    "\n",
    "Em que $\\hat{y}$ é a estimativa (ou predição) da label $y$, dados os valores das features $x_{1}, x_{2},...,x_{n}$, $(w_{1}, w_{2},...,w_{n})$ é o conjunto de pesos (weight) associado às features e $b$ é chamado de viés (bias)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e02f33",
   "metadata": {},
   "source": [
    "Vamos definir a perda (loss) associada ao modelo através da função de perda $L_{2}$, da mesma forma que foi feito no primeiro modelo. Assim:\n",
    "\n",
    "$loss = \\frac{1}{n}\\sum_{i = 1}^{n} (\\hat{y_{i}} - y_{i})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea535c",
   "metadata": {},
   "source": [
    "Nesse contexto, chamemos $\\theta = (w_{1}, w_{2}, ... , w_{n}, b)$. Além disso, definimos o hiperparâmetro $\\alpha$ como a taxa de aprendizagem do modelo, de forma análoga ao modelo anterior.\n",
    "\n",
    "Assim, por meio do gradiente descendente estocástico, o novo valor de $\\theta$, $\\theta'$, será dado pela fórmula:\n",
    "\n",
    "$\\theta' = \\theta - \\alpha \\cdot \\nabla f(w_{1}, w_{2}, ... , w_{n}, b)$\n",
    "\n",
    "Onde $\\nabla f(w_{1}, w_{2}, ... , w_{n}, b) = (\\frac{\\partial f}{\\partial w_{1}}, \\frac{\\partial f}{\\partial w_{2}},..., \\frac{\\partial f}{\\partial w_{n}}, \\frac{\\partial f}{\\partial b})$ é o gradiente de f."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64128bc",
   "metadata": {},
   "source": [
    "Calculando as derivadas parciais:\n",
    "\n",
    "$\\frac{\\partial f}{\\partial w_{k}} = \\frac{2}{n}\\sum_{i = 1}^{n} (\\hat{y}_{i} - y_{i}) \\cdot (x_{k})_{i}$, para toda feature $x_{k}$.\n",
    "\n",
    "$\\frac{\\partial f}{\\partial b} = \\frac{2}{n}\\sum_{i = 1}^{n} (\\hat{y}_{i} - y_{i})$\n",
    "\n",
    "Obtemos os novos valores do peso e do viés após uma iteração:\n",
    "\n",
    "$w_{k}' = w_{k} - \\frac{2 \\alpha}{n}\\sum_{i = 1}^{n} (\\hat{y}_{i} - y_{i}) \\cdot (x_{k})_{i}$, para toda feature $x_{k}$.\n",
    "\n",
    "\n",
    "$b' = b - \\frac{2 \\alpha}{n}\\sum_{i = 1}^{n} (\\hat{y}_{i} - y_{i})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "83e8c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Complete_Linear_Regression_Model():\n",
    "    def __init__(self, train_data, features_name: list, label_name: str, ws: list, b: float, alpha: float, random_state: int):\n",
    "        self.train_data = train_data\n",
    "        self.features = train_data[features_name]\n",
    "        self.label = train_data[label_name]\n",
    "        self.label_name = label_name # saving here because label as a series doesn't save it.\n",
    "        for i in range(0, len(ws)):\n",
    "            ws[i] = float(ws[i])\n",
    "        self.ws = np.array(ws) # weights\n",
    "        self.b = b\n",
    "        self.alpha = alpha\n",
    "        self.rand = np.random.RandomState(random_state)\n",
    "        \n",
    "    def print_parameters(self):\n",
    "        for i in range(1, len(self.ws) + 1):\n",
    "            print(f'w{i} = {self.ws[i - 1]}')\n",
    "        print (f'b = {self.b}')\n",
    "        \n",
    "    def get_single_prediction(self, xs: list):\n",
    "        '''Get the prediction for a list with all the features' values.'''\n",
    "        for i in range(0, len(xs)):\n",
    "            xs[i] = float(xs[i])\n",
    "        xs = np.array(xs)\n",
    "        pred = np.dot(self.ws, xs) + self.b\n",
    "        return pred\n",
    "    \n",
    "    def predict(self, data):\n",
    "        n = len(data)\n",
    "        features_name = self.features.columns\n",
    "        data_features = data[features_name]\n",
    "        predictions = np.zeros(n)\n",
    "        for i in range(0, n):\n",
    "            xs = list(data_features.iloc[i])\n",
    "            predictions[i] += self.get_single_prediction(xs)\n",
    "        return predictions\n",
    "    \n",
    "    def get_loss(self, data):\n",
    "        n = len(data)\n",
    "        data_label = data[self.label_name]\n",
    "        y = np.array(data_label)\n",
    "        predictions = self.predict(data)\n",
    "        diff = predictions - y\n",
    "        loss = (1/n)*np.dot(diff, diff)\n",
    "        return loss\n",
    "               \n",
    "    def sgd_update_parameters(self, batch_size: int):\n",
    "        n = len(self.label)\n",
    "        index_list = list(range(0, n))\n",
    "        random_indices = self.rand.choice(index_list, size = batch_size, replace = True) # bootstrap sample\n",
    "        xs_sample = list()\n",
    "        y_sample = np.array(self.label.iloc[random_indices])\n",
    "        preds_sample = np.zeros(batch_size)\n",
    "        for i in range(0, batch_size):\n",
    "            xs = list(self.features.iloc[random_indices[i]])\n",
    "            preds_sample[i] += self.get_single_prediction(xs)\n",
    "        for col in self.features:\n",
    "            xs_sample.append(np.array(self.features[col].iloc[random_indices])) # len(xs_sample) = len(self.ws)\n",
    "        diff_sample = preds_sample - y_sample\n",
    "        partial_w = np.zeros(len(self.ws))\n",
    "        for i in range(0, len(self.ws)):\n",
    "            partial_w[i] += (2/batch_size) * np.dot(diff_sample, xs_sample[i])\n",
    "        partial_b = (2/batch_size) * np.sum(diff_sample)\n",
    "        self.ws -= self.alpha * partial_w\n",
    "        self.b -= self.alpha * partial_b\n",
    "        \n",
    "    def sgd(self, iterations: int, batch_size: float, print_loss: bool): # stochastic gradient descent\n",
    "        for i in range(0, iterations):\n",
    "            self.sgd_update_parameters(batch_size)\n",
    "            if print_loss:\n",
    "                print(f'loss = {self.get_loss(self.train_data)}')\n",
    "    \n",
    "    @staticmethod\n",
    "    def shuffle_data(data, random_state):\n",
    "        rand = np.random.RandomState(random_state)\n",
    "        return data.reindex(rand.permutation(data.index))\n",
    "    \n",
    "    @staticmethod\n",
    "    def train_val_test_split(data, test_split: float, val_split: float):\n",
    "        '''Get train, validation and test dataframes from data.'''\n",
    "        n = len(data)\n",
    "        test_size = int(test_split * n)\n",
    "        val_size = int(val_split * n)\n",
    "        test_data = data.iloc[list(range(0, test_size))]\n",
    "        val_data = data.iloc[list(range(test_size, test_size + val_size))]\n",
    "        train_data = data.iloc[list(range(test_size + val_size, n))]\n",
    "        return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "55abfa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"GRE Score\", \"TOEFL Score\", \"University Rating\", \"SOP\", \"LOR\", \"CGPA\"]\n",
    "label = 'Chance of Admit'\n",
    "ws = [0, 0, 0, 0, 0, 0]\n",
    "b = 0\n",
    "alpha = 10**(-6)\n",
    "complete_model = Complete_Linear_Regression_Model(train_data = data, features_name = features,\n",
    "                                                 label_name = label, ws = ws, b = b, alpha = alpha,\n",
    "                                                 random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7da95491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = 0.0\n",
      "w2 = 0.0\n",
      "w3 = 0.0\n",
      "w4 = 0.0\n",
      "w5 = 0.0\n",
      "w6 = 0.0\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "complete_model.print_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c06f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_model.sgd(iterations = 1000, batch_size = 50, print_loss = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_model.get_loss(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3c5fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_model.print_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data[label])\n",
    "pred = np.zeros(n)\n",
    "pred = complete_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6be79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_pred = data.assign(Predictions = pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d9899",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
